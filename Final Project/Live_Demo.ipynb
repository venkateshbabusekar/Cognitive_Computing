{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Demo - When we downlaod the new video from you tube you can use this code for the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "import operator\n",
    "import threading\n",
    "from processor import process_image\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_path = os.path.join('data', 'youtubevideo_seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "max_frames = 300  # max number of frames a video can have for us to use it\n",
    "\n",
    "# for lstm and mlp \n",
    "\n",
    "data_type = 'features'\n",
    "features_length=2048\n",
    "input_shape = (seq_length, features_length)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################              get data \n",
    "\n",
    "with open(os.path.join('data', 'youtubevideo.csv'), 'r') as fin:\n",
    "    reader = csv.reader(fin)\n",
    "    data = list(reader)\n",
    "\n",
    "with open('classes.csv', 'r') as fin2:\n",
    "    reader = csv.reader(fin2)\n",
    "    classes = list(reader)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test():\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "    finaltest=[]\n",
    "    for item in data:\n",
    "        if item[0] == 'train':\n",
    "            train.append(item)\n",
    "        if item[0] == 'finaltest':\n",
    "            finaltest.append(item)\n",
    "        if item[0] == 'youtubevideo':\n",
    "            test.append(item)\n",
    "    return train, test, finaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_sequence(frames):\n",
    "\n",
    "    return [process_image(x, image_shape) for x in frames]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_extracted_sequence( data_type, sample):\n",
    "\n",
    "    filename = sample[1]\n",
    "    path = os.path.join(sequence_path, filename + '-' + str(seq_length) + '-' + data_type + '.npy')\n",
    "    if os.path.isfile(path):\n",
    "        return np.load(path)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_for_sample(sample):\n",
    "\n",
    "    path = os.path.join('data', sample[0])\n",
    "    filename = sample[1]\n",
    "    images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_filename_from_image(filename):\n",
    "    parts = filename.split(os.path.sep)\n",
    "    return parts[-1].replace('.jpg', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rescale_list(input_list, size):\n",
    "\n",
    "    assert len(input_list) >= size\n",
    "\n",
    "    # Get the number to skip between iterations.\n",
    "    skip = len(input_list) // size\n",
    "\n",
    "    # Build our new output.\n",
    "    output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
    "\n",
    "    # Cut off the last one if needed.\n",
    "    return output[:size]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sequences_in_memory(train_test_finaltest, data_type):\n",
    "\n",
    "    # Get the right dataset.\n",
    "    train, test, finaltest = split_train_test()\n",
    "\n",
    "    if train_test_finaltest == 'youtubevideo':\n",
    "        data= test\n",
    "    if train_test_finaltest == 'train':\n",
    "        data = train\n",
    "    if train_test_finaltest == 'finaltest':\n",
    "        data= finaltest\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test_finaltest))\n",
    "#     print(data)\n",
    "\n",
    "    X, y = [], []\n",
    "    for row in data:\n",
    "#         print(\"****************************************************\")\n",
    "\n",
    "#         print(row)\n",
    "        \n",
    "        if data_type == 'images':\n",
    "            print(row)\n",
    "            frames = get_frames_for_sample(row)\n",
    "            frames = rescale_list(frames, seq_length)\n",
    "            print(frames)\n",
    "\n",
    "            # Build the image sequence\n",
    "            sequence = build_image_sequence(frames)\n",
    "\n",
    "        else:\n",
    "            sequence = get_extracted_sequence(data_type, row)\n",
    "\n",
    "            if sequence is None:\n",
    "                print(\"Can't find sequence. Did you generate them?\")\n",
    "                raise\n",
    "\n",
    "        X.append(sequence)\n",
    "\n",
    "\n",
    "    return np.array(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get model with pretrained weights.\n",
    "base_model = InceptionV3(weights='imagenet', include_top=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll extract features at the final pool layer.\n",
    "inception_model = Model(inputs=base_model.input,outputs=base_model.get_layer('avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.02it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(data))\n",
    "for video in data:\n",
    "\n",
    "    # Get the path to the sequence for this video.\n",
    "    path = os.path.join('data', 'youtubevideo_seq', video[1] + '-' + str(seq_length) + '-features')  # numpy will auto-append .npy\n",
    "\n",
    "    # Check if we already have it.\n",
    "    if os.path.isfile(path + '.npy'):\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    # Get the frames for this video.\n",
    "    frames = get_frames_for_sample(video)\n",
    "\n",
    "    # Now downsample to just the ones we need.\n",
    "    frames = rescale_list(frames, seq_length)\n",
    "\n",
    "\n",
    "    # Now loop through and extract features to build the sequence.\n",
    "    sequence = []\n",
    "    for image_path in frames:\n",
    "        print(image_path)\n",
    "        img = image.load_img(image_path, target_size=(299, 299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Get the prediction.\n",
    "        features = inception_model.predict(x)\n",
    "\n",
    "        features = features[0]\n",
    "        \n",
    "        sequence.append(features)\n",
    "\n",
    "    # Save the sequence.\n",
    "    np.save(path, sequence)\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "from collections import deque\n",
    "import sys\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 samples into memory for youtubevideoing.\n"
     ]
    }
   ],
   "source": [
    "X_lstm_test =get_all_sequences_in_memory('youtubevideo', data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes= len(classes)\n",
    "features_length=2048\n",
    "input_shape = (seq_length, features_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model_lstm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model_lstm = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model_lstm.load_weights(\"model_lstm.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy']\n",
    "if nb_classes >= 10:\n",
    "    metrics.append('top_k_categorical_accuracy')\n",
    "    \n",
    "optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "loaded_model_lstm.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_lstm_predict = loaded_model_lstm.predict(X_lstm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label = ['ApplyLipstick']\n"
     ]
    }
   ],
   "source": [
    "num_predictions = 20\n",
    "for predict_index, predicted_y in enumerate(loaded_model_lstm_predict):\n",
    "#     actual_label = classes[np.argmax(Y_lstm_test[predict_index])]\n",
    "    predicted_label = classes[np.argmax(predicted_y)]\n",
    "    print('Predicted Label = %s' % (predicted_label))\n",
    "    if predict_index == num_predictions:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.55350462e-02,   9.31042552e-01,   3.25587948e-08,\n",
       "          7.16654611e-08,   2.48733323e-09,   6.67529832e-07,\n",
       "          3.94910728e-07,   5.03382012e-08,   9.17524901e-08,\n",
       "          3.13972492e-08,   1.54040833e-08,   4.23546638e-08,\n",
       "          3.59253609e-05,   1.15917019e-05,   7.33283088e-08,\n",
       "          2.98972680e-10,   2.44809950e-08,   4.26027533e-08,\n",
       "          6.52211725e-08,   2.38578254e-03,   7.11141368e-08,\n",
       "          1.92988399e-08,   1.32940457e-07,   7.19577019e-06,\n",
       "          6.65318964e-08,   1.32089428e-09,   1.01755809e-07,\n",
       "          1.41146739e-08,   2.02503813e-07,   8.67067513e-07,\n",
       "          6.37725464e-07,   2.54265217e-07,   6.86103760e-07,\n",
       "          5.45694027e-04,   1.17531249e-06,   5.64623917e-07,\n",
       "          1.77552035e-08,   1.37604124e-08,   6.39593125e-08,\n",
       "          1.15054320e-07,   2.22435460e-06,   3.19431711e-05,\n",
       "          3.88111948e-06,   8.93583252e-09,   3.28522987e-08,\n",
       "          3.18627440e-06,   3.27468086e-07,   3.51556722e-08,\n",
       "          2.55809907e-09,   3.43643251e-06,   2.21350085e-08,\n",
       "          1.18695045e-08,   7.86171881e-07,   1.19476808e-05,\n",
       "          9.93211202e-08,   4.37454304e-08,   2.81130319e-08,\n",
       "          8.26899349e-09,   8.28557802e-07,   9.63338948e-07,\n",
       "          8.83474698e-08,   4.04769196e-07,   5.38900963e-07,\n",
       "          6.36771214e-09,   4.97650010e-09,   1.20235554e-05,\n",
       "          1.13877121e-07,   1.83375434e-07,   6.73716514e-08,\n",
       "          2.50107234e-07,   6.30054373e-08,   9.14025744e-09,\n",
       "          8.45066417e-09,   6.06944468e-08,   1.82040651e-06,\n",
       "          2.14924768e-07,   7.36648587e-07,   3.41089850e-04,\n",
       "          5.38414717e-08,   4.44758452e-09,   1.11320713e-08,\n",
       "          1.30289091e-09,   2.29837241e-07,   8.01988875e-09,\n",
       "          9.70768141e-08,   5.72980987e-08,   7.00999749e-07,\n",
       "          3.91424404e-09,   3.67574586e-07,   6.87170099e-10,\n",
       "          4.94048358e-10,   3.48804763e-09,   2.73833393e-06,\n",
       "          4.17366870e-08,   1.57414934e-06,   7.86540468e-08,\n",
       "          2.24472476e-08,   2.18303171e-08,   4.11127894e-06,\n",
       "          2.82936867e-07,   1.49912148e-06]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_lstm_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
